NEO4J_URI=bolt://localhost:7687
NEO4J_USERNAME=neo4j
NEO4J_PASSWORD=password
NEO4J_DATABASE=neo4j
EMBEDDING_MODEL=Qwen/Qwen3-Embedding-0.6B
RAGAS_EMBEDDING_MODEL=Qwen/Qwen3-Embedding-0.6B       #Keep blank if you want to use all-MiniLM-L6-v2 for ragas embeddings
IS_EMBEDDING=TRUE
KNN_MIN_SCORE=0.94
NUMBER_OF_CHUNKS_TO_COMBINE=6
UPDATE_GRAPH_CHUNKS_PROCESSED=20
MAX_TOKEN_CHUNK_SIZE=2000                   #Max token used to process/extract the file content.

ENTITY_EMBEDDING=TRUE                        # TRUE or FALSE based on whether to create embeddings for entities suitable for entity vector mode
DUPLICATE_SCORE_VALUE=0.97
DUPLICATE_TEXT_DISTANCE=3
EFFECTIVE_SEARCH_RATIO=5

# CON GROQ
MODEL_NAME=openai/gpt-oss-120b
GRAPH_CLEANUP_MODEL=groq_gpt-oss-120b
LLM_MODEL_CONFIG_groq_gpt-oss-120b=gpt-oss-120b,https://api.groq.com/openai/v1/models,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

# CON OLLAMA
#GRAPH_CLEANUP_MODEL=ollama_qwen2.5_7b
#LLM_MODEL_CONFIG_ollama_qwen2.5_7b=qwen2.5:7b,http://localhost:11434
#MODEL_NAME=qwen2.5:7b




GEMINI_ENABLED=False
GCP_LOG_METRICS_ENABLED=False # Enable Google Cloud logs (default is False) | Can be False or True
DEFAULT_DIFFBOT_CHAT_MODEL=openai_gpt_4o  #whichever model specified here , need to add config for that model in below format)
LLM_MODEL_CONFIG_openai_gpt_3.5=gpt-3.5-turbo-0125,openai_api_key
LLM_MODEL_CONFIG_openai_gpt_4o_mini=gpt-4o-mini-2024-07-18,openai_api_key
LLM_MODEL_CONFIG_openai_gpt_4o=gpt-4o-2024-11-20,openai_api_key
LLM_MODEL_CONFIG_openai_gpt_4.1_mini=gpt-4.1-mini,openai_api_key
LLM_MODEL_CONFIG_openai_gpt_4.1=gpt-4.1,openai_api_key
LLM_MODEL_CONFIG_openai_gpt_o3_mini=o3-mini-2025-01-31,openai_api_key
LLM_MODEL_CONFIG_gemini_1.5_pro=gemini-1.5-pro-002
LLM_MODEL_CONFIG_gemini_1.5_flash=gemini-1.5-flash-002
LLM_MODEL_CONFIG_gemini_2.0_flash=gemini-2.0-flash-001
LLM_MODEL_CONFIG_gemini_2.5_pro=gemini-2.5-pro
LLM_MODEL_CONFIG_diffbot=diffbot,diffbot_api_key
LLM_MODEL_CONFIG_azure_ai_gpt_35=azure_deployment_name,azure_endpoint or base_url,azure_api_key,api_version
LLM_MODEL_CONFIG_azure_ai_gpt_4o=gpt-4o,https://YOUR-ENDPOINT.openai.azure.com/,azure_api_key,api_version
LLM_MODEL_CONFIG_anthropic_claude_4_sonnet=model_name,anthropic_api_key    #model_name=claude-sonnet-4-20250514
LLM_MODEL_CONFIG_fireworks_llama4_maverick=model_name,fireworks_api_key
YOUTUBE_TRANSCRIPT_PROXY=https://user:pass@domain:port
BEDROCK_EMBEDDING_MODEL=model_name,aws_access_key,aws_secret_key,region_name                       #model_name=amazon.titan-embed-text-v1
LLM_MODEL_CONFIG_bedrock_nova_micro_v1=model_name,aws_access_key,aws_secret_key,region_name        #model_name=amazon.nova-micro-v1:0
LLM_MODEL_CONFIG_bedrock_nova_lite_v1=model_name,aws_access_key,aws_secret_key,region_name         #model_name=amazon.nova-lite-v1:0
LLM_MODEL_CONFIG_bedrock_nova_pro_v1=model_name,aws_access_key,aws_secret_key,region_name          #model_name=amazon.nova-pro-v1:0
LLM_MODEL_CONFIG_fireworks_deepseek_r1=model_name,fireworks_api_key      #model_name=accounts/fireworks/models/deepseek-r1
LLM_MODEL_CONFIG_fireworks_deepseek_v3=model_name,fireworks_api_key      #model_name=accounts/fireworks/models/deepseek-v3

#GCS_FILE_CACHE =  #save the file into GCS or local, SHould be True or False
#NEO4J_USER_AGENT=
#ENABLE_USER_AGENT =
#LLM_MODEL_CONFIG_model_version=
#OPENAI_API_KEY =    #This is required if you are using openai embedding model
#AWS_ACCESS_KEY_ID =
#AWS_SECRET_ACCESS_KEY =
#LANGCHAIN_API_KEY =
#LANGCHAIN_PROJECT =
#LANGCHAIN_TRACING_V2 =